<!DOCTYPE html><!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Fri Feb 12 2021 06:13:30 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="600e4f00f94c72f618b5cca0" data-wf-site="5ffff08ec0ca0118c7ab2543">
<head>
  <meta charset="utf-8">
  <title>Moderating online harassment using design and textual interventions</title>
  <meta content="Moderating online harassment using design and textual interventions" property="og:title">
  <meta content="Moderating online harassment using design and textual interventions" property="twitter:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/portfolio-428471-0d7ea5c9c1c97c25df82a1.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Varela Round:400","Roboto:100italic,300,300italic,regular,italic,500,500italic,700,700italic,900,900italic:vietnamese,cyrillic-ext,greek-ext,greek,latin-ext,latin,cyrillic"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.png" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
</head>
<body class="body-3">
  <div class="main-page">
    <div data-collapse="medium" data-animation="default" data-duration="400" data-doc-height="1" data-w-id="61e8e957-5bd7-b851-2012-4e9925ce073a" role="banner" class="navbar-2 navbar-1 w-nav">
      <div class="container-2 w-container">
        <a href="index.html" class="link-block-7 w-inline-block"><img src="images/shriyalogo.png" width="43" id="Main-page" alt="" class="image-9"></a>
        <div class="menu-button w-nav-button">
          <div class="w-icon-nav-menu"></div>
        </div>
        <nav role="navigation" class="nav-menu w-nav-menu">
          <a href="index.html" class="link-nav w-nav-link"> üè† Home</a>
          <a href="about.html" class="link-nav w-nav-link">üë© About</a>
          <a href="documents/ShriyaHardikar_Resume.pdf" target="_blank" class="link-nav w-nav-link">üìÉ Resume</a>
        </nav>
      </div>
    </div>
  </div>
  <div class="proj-heading-block">
    <h2 class="heading-title">Moderating online harassment using design and textual interventions</h2>
<!--     <p class="paragraph-32">A smart crate system that decreases disruptive barking in dogs using positive reinforcement and stimulus masking methods.</p> -->
  </div>
  <div class="image-proj"><img src="images/10m53krooMnz1E4Q-e9P2Jg.png" sizes="(max-width: 1400px) 100vw, 1400px" srcset="images/10m53krooMnz1E4Q-e9P2Jg-p-500.png 500w, images/10m53krooMnz1E4Q-e9P2Jg-p-800.png 800w, images/10m53krooMnz1E4Q-e9P2Jg-p-1080.png 1080w, images/10m53krooMnz1E4Q-e9P2Jg.png 1400w" alt="" class="image-11-copy"></div>
  <div class="proj-content">
    <div class="team-info">
      <div class="team-info-each">
        <p class="paragraph-35">Advisor</p>
        <p class="paragraph-36">
          <a href="https://en.wikipedia.org/wiki/Cliff_Lampe" target="_blank" class="link-29">Prof. Clifford Lampe (UMSI) </a>
        </p>
        <p class="paragraph-35">Team </p>
        <p class="paragraph-36">Song Mi Lee (PhD student) Prof. Clifford Lampe (UMSI)<br></p>
      </div>
      <div class="team-info-each">
        <p class="paragraph-35">Duration</p>
        <p class="paragraph-36">August 2019 - May 2020<br></p>
      </div>
      <div class="team-info-each">
        <p class="paragraph-35">Role</p>
        <p class="paragraph-36">Researcher</p>
      </div>
      <div class="team-info-each">
        <p class="paragraph-35">Skills</p>
        <p class="paragraph-36">Literature review, Survey building, Quantitative Analysis, Statistical Analysis</p>
        <p class="paragraph-35">Statistical test used<br></p>
        <p class="paragraph-36">One-way ANOVA, Welch ANOVA, Factor Analysis, Chi-Square test, Two-way ANOVA, Between-subject factor analysis, Levene&#x27;s test<br></p>
      </div>
      <div class="team-info-each">
        <p class="paragraph-35">Tools</p>
        <p class="paragraph-36">IBM SPSS, Prolific.com, Qualtrics<br></p>
      </div>
    </div>
    <div class="proj-sections">
      <h2 class="heading-9">Overview <span class="text-span-3">üìë</span></h2>
      <p class="paragraph-34">In the Winter of 2019 I took a course of Online Communities with Prof. Clifford Lampe. One of the major topic we dived into was that of online harassment. I was intrigued by this under explored topic and I decided to work on an independent project with Prof. Clifford. Instead of exploring an altogether new project to work on, we decided to work on a study which was already conducted. ‚Äú<a href="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17902/16993" target="_blank" class="link-24">When Online Harassment Is Perceived as Justified</a>‚Äù was paper published by Lindsay Blackwell, Tianying Chen, Sarita Schoenebeck, and Clifford Lampe. Lindsay‚Äôs paper talks about user‚Äôs perception of online harassment with the respect to retributive justice. It also explores the role of bystander intervention in reducing online harassment.<br><br>In this study we closely look at the <span class="text-span-62">role of <strong>visual</strong> and <strong>textual</strong> cues to understand its effects on user‚Äôs perception of normative behavior, and retributive harassment. In my this article</span>. I will exclusively talk about how visual design plays a role in moderating harassment.<br><em><br>‚Äç</em>Before we dive into the specifics of this project there are some terms and theories one has to be familiar with.In the Winter of 2019 I took a course of Online Communities with Prof.</p>
      <div class="proj-image-bari"><img src="images/Screen-Shot-2021-02-07-at-4.38.54-PM.png" sizes="(max-width: 479px) 75vw, (max-width: 767px) 80vw, (max-width: 991px) 56vw, 60vw" srcset="images/Screen-Shot-2021-02-07-at-4.38.54-PM-p-500.png 500w, images/Screen-Shot-2021-02-07-at-4.38.54-PM-p-800.png 800w, images/Screen-Shot-2021-02-07-at-4.38.54-PM-p-1080.png 1080w, images/Screen-Shot-2021-02-07-at-4.38.54-PM.png 1552w" alt="" class="image-12">
        <div class="proj-image-caption"><em>Here is what Prof. Clifford Lampe has to say - </em>
          <a href="https://www.linkedin.com/in/shriyahardikar/"><em class="italic-text-10">LinkedIn</em></a><em><br></em>
        </div>
      </div>
    </div>
    <div class="design-def">
      <div class="text-block-42">Design Problem üíÅ </div>
      <p class="paragraph-38">How can visual and textual cues help mitigate online harassment?<br></p>
    </div>
    <div class="proj-sections">
      <h2 class="heading-9">Concepts üß©<span class="text-span-3"><br></span></h2>
      <div data-duration-in="300" data-duration-out="100" class="tabs-3 w-tabs">
        <div class="tabs-menu-4 w-tab-menu">
          <a data-w-tab="Tab 1" class="tab-name-2 w-inline-block w-tab-link w--current">
            <div class="text-block-68">Online Harassment</div>
          </a>
          <a data-w-tab="Tab 2" class="tab-link-tab-2-3 tab-name-2 w-inline-block w-tab-link">
            <div class="text-block-69">Retributive Harassment</div>
          </a>
          <a data-w-tab="Tab 3" class="tab-link-tab-3-2 tab-name-2 w-inline-block w-tab-link">
            <div class="text-block-70">Normative Cue</div>
          </a>
          <a data-w-tab="Tab 4" class="tab-link-tab-4-3 tab-name-2 w-inline-block w-tab-link">
            <div class="text-block-71">Signalling Theory</div>
          </a>
        </div>
        <div class="tabs-content w-tab-content">
          <div data-w-tab="Tab 1" class="tab-pane-tab-1-2 w-tab-pane w--tab-active">
            <p class="paragraph-3499">The definition of online harassment varies from people to people and even circumstances. It includes online settings such as email, social media platforms, messaging apps, blogs, and more. Activities like cyberbullying, DoS attacks, doxing, trolling, swatting, public shaming etc, come under the umbrella of <a href="https://onlineharassmentfieldmanual.pen.org/defining-online-harassment-a-glossary-of-terms/" class="link-25">online harassment</a>. Justine Sacco was the victim of public shaming, cyberbullying, and mob-driven harassment.<br><br>In December of 2013, Justine Sacco, a PR executive at the IAC, took a plane from New York to Cape Town. Just before boarding Justine tweeted to her 170 Twitter followers, <br>The definition of online harassment varies from people to people and even circumstances. It includes online settings such as email, social media platforms, messaging apps, blogs, and more. Activities like cyberbullying, DoS attacks, doxing, trolling, swatting, public shaming etc, come under the umbrella of</p>
            <blockquote class="block-quote"><strong class="bold-text-50">‚ÄúGoing to Africa. Hope I don‚Äôt get AIDS. Just kidding. I‚Äôm white!‚Äù.</strong></blockquote>
            <p class="paragraph-3499">The tweet received extreme backlash from the Twitteratis. By the time she landed in Cape Town, she had lost her job and was the number one trending on Twitter with a <strong>#HasJustineLandedYet</strong>.</p>
            <div class="proj-image-bari"><img src="images/Justine-Sacco-008.jpg" alt="" class="image-12">
              <div class="proj-image-caption">
                <a href="https://www.theguardian.com/world/2013/dec/22/pr-exec-fired-racist-tweet-aids-africa-apology" target="_blank" class="link-26">The Guardian</a>
              </div>
            </div>
          </div>
          <div data-w-tab="Tab 2" class="w-tab-pane">
            <p class="paragraph-3499">Lindsay Blackwell defines retributive justice as ‚ÄúIt refers to a theory of punishment in which individuals who <strong class="bold-text-51">knowingly commit an act deemed to be morally wrong receive a proportional punishment for their misdeeds, sometimes referred to as an eye for an eye</strong>‚Äù. Even Kant‚Äôs idea of justice revolved around punishing the perpetrators in proportion to their ‚Äòinternal wickedness‚Äô and the need for punishment is derived from a ‚Äòuniversal goal of giving people what they deserve‚Äô.</p>
          </div>
          <div data-w-tab="Tab 3" class="w-tab-pane">
            <p class="paragraph-3499">Norms are a way of behaving that are considered normal, standard or typical for that community or institution. Normative cues are the signals that help any external entity understand the norms of that community/institution. Cues are often subtle with some <strong class="bold-text-52">cues </strong>being stickier than others ‚Äî likes, hearts, retweets, karma points, badges, etc. Cues such as flags, likes, dislikes, etc. convey people‚Äôs approval and disapproval that stimulate judgment about norms, especially when the norms are not salient.</p>
          </div>
          <div data-w-tab="Tab 4" class="w-tab-pane">
            <p class="paragraph-3499">Much of that people want to know about each other is not directly observable face-to-face or online. Much like real world, in a online mediated environment people constantly try to observe cues or signals about how they are perceived. Conventional signals are the signals that can be easily faked (eg. Profile name, age, gender, etc.), where as, Assessment signals are hard to fake (eg. Statuses like top contributor, number of likes/dislikes, tags etc). Warranting is a signal or a <strong class="bold-text-53">cue</strong> which is coming from a neutral party, and is hard to fake (like assessment signals).</p>
          </div>
        </div>
      </div>
    </div>
    <div class="proj-sections-3">
      <h2 class="heading-9">Lindsay&#x27;s Original Study<span class="text-span-3"><br></span></h2>
      <p class="paragraph-34">As previously mentioned, this study is inspired from Lindsay Blackwell‚Äôs paper on retributive harassment. In order to understand our study, it is necessary to understand Lindsay‚Äôs experiment.Figure 1 : Conformity + Bystander condition that was shown in Lindsay‚Äôs paper.Lindsay Blackwell‚Äôs <a href="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17902/16993" target="_blank">paper</a> discusses user‚Äôs perception of online harassment w.r.t retributive justice. She conducted 2 studies which tested the attitudes of participants about online harassment, effects of social conformity, and bystander intervention. On the contrary to popular belief, her experiment concluded that ‚Äú<em>people believe online harassment is more deserved and more justified ‚Äî but not more appropriate ‚Äî when the target has committed some offense.</em>‚Äù Additionally, the experiment also suggested that the bystander intervention (<strong>bystander</strong> is a person who observes the situation and makes a call to intervene or not) reduces the perception of a harassment being more deserved or justified. Participant were randomly shown offensive post along with a control, a low retributive prime, and high retributive prime. In experiment 2, participants were exposed to the conditions of control, conformity, and conformity + bystander.<br></p>
      <div class="div-block-36"><img src="images/1_u5-TGoymmQod5xNFfn_zWQ.png" width="600" alt="" class="image-16"></div>
    </div>
    <div class="proj-sections-copy">
      <h2 class="heading-9-copy">Key Research Questions<span class="text-span-3"><br></span></h2>
      <p class="paragraph-345">1. Can visual cues mitigate online harassment?<br><br>2. Can visual cues reduce retributive harassment?<br><br>3. Can assessment signals be used to reduce harassment?<br></p>
    </div>
  </div>
  <div class="proj-info">
    <div class="maiin-block">
      <div class="div-block-355"><img src="images/Untitled.png" loading="lazy" sizes="80vw" srcset="images/Untitled-p-500.png 500w, images/Untitled.png 1288w" alt="" class="image-22"></div>
      <div class="div-block-356">
        <h2 class="research-heading">Research<br>‚Üì<span class="text-span-3"><br></span></h2>
      </div>
      <div data-duration-in="300" data-duration-out="100" class="w-tabs">
        <div class="tabs-menu-5 w-tab-menu">
          <a data-w-tab="Tab 1" class="tab-name w-inline-block w-tab-link w--current">
            <div>Overview</div>
          </a>
          <a data-w-tab="Tab 2" class="tab-name w-inline-block w-tab-link">
            <div>Pretest 1</div>
          </a>
          <a data-w-tab="Tab 3" class="tab-name w-inline-block w-tab-link">
            <div>Pretest 2</div>
          </a>
          <a data-w-tab="Tab 4" class="tab-name w-inline-block w-tab-link">
            <div>Pretest 3</div>
          </a>
        </div>
        <div class="w-tab-content">
          <div data-w-tab="Tab 1" class="w-tab-pane w--tab-active">
            <div class="proj-sections">
              <h2 class="heading-9">Overview <span class="text-span-3">üëÅÔ∏è<br></span></h2>
              <p class="paragraph-34">As mentioned in the previous overview section, this experiment looks at the role of <strong>visual</strong> and <strong>textual</strong> cues to understand its effects on user‚Äôs perception of normative behavior, and retributive harassment. During conducting this study, we performed 3 pretest, each one affecting the setup of the next one. <br><br>In this overview section I will be briefly talking about all three pretest and their results. For a detailed analysis of each pretest please check the tab section above.</p>
              <div class="proj-image-bari"><img src="images/Frame-1_3.png" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/Frame-1-p-500.png 500w, images/Frame-1-p-800.png 800w, images/Frame-1_3.png 1392w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Each pretest affects the setting of the next one<br></em></div>
              </div>
              <p class="paragraph-42">Pretest 1 üß™</p>
              <p class="paragraph-34">The survey was designed in Qualtrics, and tested using <a href="http://prolific.co/" target="_blank" class="link-27">Prolific</a>. This survey was tested on 180 participants. The 6 conditions tested were : P1 ‚Äî Control (29), P2 ‚ÄîLikes (29), and P3 ‚Äî Dislike (40), P4 ‚Äî Reported Control (36), P5 ‚Äî Reported Harassment (26), and P6 ‚Äî Reported Count (20).<br><span class="text-span-63">The design interventions acted as evaluative <strong>cues</strong>.</span> Example: If a user on the social media is subjected to a harassment post along with a statement that the post has been reported for harassment, in an ideal case scenario, the user will hold back from making a mean or harassing comment to it. This is because a reporting cue acted a an assessment signal for the user. As mentioned before assessment signals are hard to fake, and if the post has been reported for harassment by other community members, it helps the user decide on what is normative in the community.A harassment is bound to have participation for other members, and our conformity(escalating comments) and bystander interventions(de-escalating comments) did the part. We wanted to compare how our design interventions acted infront of conformity and bystander intervention. In an ideal scenario, the values of the Likert scale for de-escalating comments and disapproving design interventions should have been negative ranging mostly into absolutely inappropriate, absolutely unjustified, and absolutely undeserved ‚Äî as there are more than one disapproving cues present. Similarly, values of the Likert scale for escalating comments and disapproving design interventions should have been in between inappropriate, unjustified and undeserved ‚Äî as there is a mix of approving and disapproving cues. Unfortunately, the results that we got did not conclusively back our hypothesis.<br><br></p>
              <blockquote class="block-quote"><strong class="bold-text-50"><em class="italic-text-7">This led us to re-evaluate our experiment conditions. Participants were subjected to evaluative cues (approval and disapproval), along with conformity and bystander interventions, and a strong prompt of the harassment. </em></strong>Basically, participants were subjected to many cues, with led them to evaluate lot of signals on a single prompt.</blockquote>
              <p class="paragraph-42">Pretest 2 üß™</p>
              <p class="paragraph-34">Quantitative statistical methods such as Two-way ANOVA, Between subject factor Analysis, and Levene‚Äôs test were used to analyze the survey results. The results of Two way ANOVA are statistically significant. As the test was conducted recently, we are still working on analyzing the data. Here is a brief overview of the analysis data we found using a correlation matrix.<br>As you can see in the above table the means for appropriate vary between absolutely inappropriate to inappropriate on a Likert scale. Similarly, means of deserved variable vary between slightly undeserved to neutral. As you can observe that the means of reported+count prompt are less than the remaining two flagging prompts, which signifies that flagging with count was considered more inappropriate, slightly undeserved, and not justified as compared to other two flagging variables. This showed us that our design interventions were definitely resulting in a reaction from the participants, but the reaction was not enough for a conclusive analysis.<br><br>We realized that if given with harassment, participants formed their own opinions on whether the harassment was appropriate, justified, or deserved. With the introduction of our design intervention, we wanted to shift those opinions to inappropriate, undeserved, or unjustified. But if the harassment itself was highly aggressive, we found that these moderating cues were ineffective. This realization opened new avenues for us.<br></p>
              <blockquote class="block-quote"><em>These pretest helped us realize that we were ignoring another factor that was affecting how people perceived harassment ‚Äî </em><strong><em>the harassment itself.</em></strong><em> The harassment prompt of ‚ÄúYou‚Äôre a f**k**g c**t. Do the world a favor and kill yourself.‚Äù was a high aggression harassment.</em><strong class="bold-text-50"><em class="italic-text-7"> </em></strong></blockquote>
              <p class="paragraph-42">Pretest 3 üß™</p>
              <p class="paragraph-34">The survey was designed in Qualtrics and tested using <a href="http://prolific.co/" target="_blank">Prolific</a>. This survey was tested on 180 participants. The 6 conditions tested were : P1 ‚Äî Low Aggression + Control (31), P2 ‚Äî Low Aggression + Dislikes (38), and P3 ‚Äî Low Aggression + Reported (27), P4 ‚Äî High Aggression + Control (33), P5 ‚Äî Low Aggression + Dislike (28), and P6 ‚Äî Low Aggression + Reported (24).<br><strong>To understand how the design intervention of original, dislike and reported affected the user‚Äôs perception of harassment </strong>I decided to compare the Likert scale means between LAH and HAH variables. Here are some of my findings:<br><br>‚Ü≥ It is surprising to find that the low aggression harassment participants (LAH) found harassment more appropriate, deserved, and justified than the high aggression harassment participants. LAH participants also agreed more with the harassment. This gives us a better idea of how the language of harassment itself can make a difference in the perception of justice.<br><br>‚Ü≥ Similarly, the high aggression participants (HAH) found the post more offensive.<br><br>‚Ü≥ The likeliness of disliking Amy‚Äôs post, and adding a comment to the post was higher in the HAH. This could be a result of the post being more aggressive than the LAH. It might very well signify that users tend to intervene if the harassment is aggressive.<br><br>‚Ü≥ Also, the likeliness of calling out Amy as well as calling out Sarah was higher in the HAH prompts which featured dislike and report intervention.<br><br>‚Ü≥ Participants with dislike prompts were more offended by the post as compared to the reported ones. This could mean that their feeling of offense could stem from others disliking the post. It could also be an effect of users perceiving reporting as a system‚Äôs intervention.<br><br>‚Ü≥ The likeliness of disliking Amy‚Äôs post and calling out Sarah was higher in the dislike prompt as compared to the report.<br><br>‚Ü≥ Participants with the reported prompt found harassment to be more deserved and agreed more with the harassment than the dislike prompt. Also, the likeliness of calling out Amy was higher in the reported as compared to dislike prompt. It could be a result of reporting being a system intervention or reporting being a more serious cue than dislike, which is a cue assessed by the community.<br></p>
            </div>
          </div>
          <div data-w-tab="Tab 2" class="w-tab-pane">
            <div class="proj-sections">
              <h2 class="heading-9">Overview <span class="text-span-3">üëÅÔ∏è<br></span></h2>
              <div class="proj-image-bari"><img src="images/1B-O6EBFOMlKKXvGYG1C0ZA.jpeg" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1B-O6EBFOMlKKXvGYG1C0ZA-p-500.jpeg 500w, images/1B-O6EBFOMlKKXvGYG1C0ZA-p-800.jpeg 800w, images/1B-O6EBFOMlKKXvGYG1C0ZA.jpeg 1000w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Prompts tested for Pretest 1<br></em></div>
              </div>
              <p class="paragraph-34">Pretest 1 tested design variations over textual variation. The design variations we used were Control, Like, Dislike and Reported. Similarly, textual variations we used comprised of no comments, escalating comments (comments that harassed Sarah) and de-escalating comments (comments that called out Amy and the harassment). This study used a <strong>3x4 factorial</strong>, between-subject design; ie. we were testing 12 conditions. Instead of final testing over all 12 conditions we decided to pretest over 3 conditions.</p>
              <div class="proj-image-bari"><img src="images/1k6B4QI-kdAmGcZHIV3a0Gg.png" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1k6B4QI-kdAmGcZHIV3a0Gg-p-500.png 500w, images/1k6B4QI-kdAmGcZHIV3a0Gg-p-800.png 800w, images/1k6B4QI-kdAmGcZHIV3a0Gg.png 1028w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Design variation and textual variation that were tested in Pretest 1<br></em></div>
              </div>
            </div>
            <div class="proj-sections">
              <h2 class="heading-9">What was tested üß™<span class="text-span-3"><br></span></h2>
              <p class="paragraph-34">The survey was designed in Qualtrics, and distributed on various social channels such as Reddit (<a href="https://www.reddit.com/r/SampleSize/" target="_blank">r/SampleSize</a>), Twitter, and Facebook using personal and anonymous connections. 59 random users participated in this survey. The 3 conditions tested were : P1 ‚Äî Reported + Escalating comments (22), P2 ‚Äî Like + De-escalating comments (12), and P3 ‚Äî Dislike + Escalating comments(25).<br>The participants were shown 1 condition prompt. The survey asked participants:<br><br>‚Ü≥ their perceptions of justice over 4 dependent variable ‚Äî <strong>appropriateness, deservedness, justifiability, and likeliness to participate</strong><br><br>‚Ü≥ an <strong>intervention orientation questionnaire</strong> which tested their attitudes related to the conditions they were shown. Example: How likely do you think it is that people would harass you if you posted a comment on this thread?<br><br>‚Ü≥ <strong>punishment orientation questionnaire</strong> tested their orientation towards different form of punishments<br><br>‚Ü≥ <strong>Canadian internet usage survey</strong> which tested participant‚Äôs internet usage and behavior<br><br>‚Ü≥ <strong>feature recall</strong> which tested the number of design variation that the participant spotted in the prompt</p>
              <h4 class="heading-16">Hypothesis</h4>
              <p class="paragraph-34"><strong><em>Hypothesis 1:</em></strong><em> Exposure to warranting cues such as number of dislikes &amp; reporting decreased the belief that retributive justice is appropriate, deserved or justified.<br><br>‚Äç</em><strong><em>Hypothesis 2:</em></strong><em> Exposure to warranting cues such as number of dislikes, &amp; reporting along with conformity (escalating comments) decreases the belief that retributive justice is appropriate, deserved or justified.<br><br>‚Äç</em><strong><em>Hypothesis 3</em></strong><em>: Exposure to warranting cues such as number of likes along with conformity (escalating comments) increases the belief that retributive justice is appropriate, deserved or justified.<br><br>‚Äç</em><strong><em>Hypothesis 4</em></strong><em>: Exposure to warranting cues such as number of likes along with bystander (de-escalating comments) decreases the belief that retributive justice is appropriate, deserved or justified.<br><br>‚Äç</em><strong><em>Hypothesis 5</em></strong><em>: Exposure to warranting cues such as number of dislikes, &amp;reporting along with bystander (de-escalating comments) decreases the belief that retributive justice is appropriate, deserved or justified.</em></p>
              <h2 class="heading-9">Findings üî¨<span class="text-span-3"><br></span></h2>
              <p class="paragraph-34">Quantitative statistical methods such as One-way ANOVA, Welch ANOVA, Factor Analysis, and Chi-square test were used to analyze the survey results. Using One-way ANOVA with a p-value of 0.05, <strong>no statistically significant results were observed. </strong>Additionally, there was a higher standard deviation observed for every evaluative question asked. High standard deviation signaled that the values of participant‚Äôs responses were spread out from the mean.<br><br>The design interventions acted as evaluative <strong>cues</strong>. Example: If a user on the social media is subjected to a harassment post along with a statement that the post has been reported for harassment, in an ideal case scenario, the user will hold back from making a mean or harassing comment to it. This is because a reporting cue acted a an assessment signal for the user. As mentioned before assessment signals are hard to fake, and if the post has been reported for harassment by other community members, it helps the user decide on what is normative in the community.<br><br>A harassment is bound to have participation for other members, and our conformity(escalating comments) and bystander interventions(de-escalating comments) did the part. We wanted to compare how our design interventions acted in-front of conformity and bystander intervention. In an ideal scenario, the values of the Likert scale for de-escalating comments and disapproving design interventions should have been negative ranging mostly into absolutely inappropriate, absolutely unjustified, and absolutely undeserved ‚Äî as there are more than one disapproving cues present. Similarly, values of the Likert scale for escalating comments and disapproving design interventions should have been in between inappropriate, unjustified and undeserved ‚Äî as there is a mix of approving and disapproving cues. Unfortunately, the results that we got did not conclusively back our hypothesis.</p>
              <blockquote class="block-quote"><em>This led us to re-evaluate our experiment conditions. Participants were subjected to evaluative cues (approval and disapproval), along with conformity and bystander interventions, and a strong prompt of the harassment. </em><strong><em class="italic-text-8">Basically, participants were subjected to many cues, with led them to evaluate lot of signals on a single prompt.</em></strong></blockquote>
              <div class="w-embed w-iframe"><iframe src="https://giphy.com/embed/ouE6OPO1MADM4" width="480" height="360" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
                <p>
                  <a href="https://giphy.com/gifs/ouE6OPO1MADM4">via GIPHY</a>
                </p>
              </div>
            </div>
          </div>
          <div data-w-tab="Tab 3" class="w-tab-pane">
            <div class="proj-sections">
              <h2 class="heading-9">Overview <span class="text-span-3">üëÅÔ∏è<br></span></h2>
              <div class="proj-image-bari"><img src="images/1hEY2fzeme23hS5xvTWb68w.jpeg" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1hEY2fzeme23hS5xvTWb68w-p-500.jpeg 500w, images/1hEY2fzeme23hS5xvTWb68w-p-800.jpeg 800w, images/1hEY2fzeme23hS5xvTWb68w.jpeg 1000w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Prompts tested for Pretest 2<br></em></div>
              </div>
              <p class="paragraph-34">Pretest 1 tested design variations over textual variation. In Pretest-2 we decided to entirely drop textual variations we were testing and focus just on design interventions. The design variations tested for this experiement were Control, Like, Dislike, Reported, Reported Harassment, and Reported Count. This study used a<strong> 1x6 factorial</strong>, between-subject design; ie. we were testing 6 conditions. The final pretest tested all 6 conditions.</p>
              <div class="proj-image-bari"><img src="images/19n5s4Nia1IZeowrE6lRzkA.jpeg" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/19n5s4Nia1IZeowrE6lRzkA-p-500.jpeg 500w, images/19n5s4Nia1IZeowrE6lRzkA.jpeg 739w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Design variation and textual variation that were tested in Pretest 2<br></em></div>
              </div>
            </div>
            <div class="proj-sections">
              <h2 class="heading-9">What was tested üß™<span class="text-span-3"><br></span></h2>
              <p class="paragraph-34">The survey was designed in Qualtrics, and tested using <a href="http://prolific.co/" target="_blank">Prolific</a>. This survey was tested on 180 participants. The 6 conditions tested were : P1 ‚Äî Control (29), P2 ‚ÄîLikes (29), and P3 ‚Äî Dislike (40), P4 ‚Äî Reported Control (36), P5 ‚Äî Reported Harassment (26), and P6 ‚Äî Reported Count (20).<br>The participants were shown 1 condition prompt. The survey asked participants:<br><br>‚Ü≥ their perceptions of justice over 3 dependent variable ‚Äî <strong>appropriateness, deservedness, and justifiability</strong><br><br>‚Ü≥ <strong>intervention orientation questionnaire </strong>which tested their attitudes related to the conditions they were shown. Example: How likely do you think it is that people would harass you if you posted a comment on this thread?<br><br>‚Ü≥ <strong>feature recall</strong> which tested the number of design variation that the participant spotted in the prompt</p>
              <h4 class="heading-16">Hypothesis</h4>
              <p class="paragraph-34"><strong><em>Hypothesis 1:</em></strong><em> Exposure to warranting cues such as number of dislikes &amp; reporting decreases the belief that retributive justice is appropriate, deserved or justified.<br><br>‚Äç</em><strong><em>Hypothesis 2:</em></strong><em> Exposure to warranting cues such as number of likes increases the belief that retributive justice is appropriate, deserved or justified.<br><br>‚Äç</em><strong><em>Hypothesis 3</em></strong><em>: Exposure to warranting cues such as the number of flags decreases the belief that retributive justice is appropriate, deserved or justified as compared to just flagged.</em>The participants were shown 1 condition prompt. The survey asked participants:<br><br>‚Ü≥ their perceptions of justice over 3 dependent variable ‚Äî <strong>appropriateness, deservedness, and justifiability</strong><br><br>‚Ü≥ <strong>intervention orientation questionnaire </strong>which tested their attitudes related to the conditions they were shown. Example: How likely do you think it is that people would harass you if you posted a comment on this thread?<br><br>‚Ü≥ <strong>feature recall</strong> which tested the number of design variation that the participant spotted in the prompt</p>
              <div class="proj-image-bari"><img src="images/19n5s4Nia1IZeowrE6lRzkA.jpeg" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/19n5s4Nia1IZeowrE6lRzkA-p-500.jpeg 500w, images/19n5s4Nia1IZeowrE6lRzkA.jpeg 739w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Design variation and textual variation that were tested in Pretest 2<br></em></div>
              </div>
            </div>
            <div class="proj-sections">
              <h2 class="heading-9">Findings üî¨<span class="text-span-3"><br></span></h2>
              <p class="paragraph-34">Quantitative statistical methods such as One-way ANOVA, Factor Analysis, and Chi-square test were used to analyze the survey results. Using One-way ANOVA with a p-value of 0.05, no statistically significant results were observed.Figure : Descriptive Statistics table of dependent variablesAs you can see in the above table the means for appropriate vary between absolutely inappropriate to inappropriate on a Likert scale. Similarly, means of deserved variable vary between slightly undeserved to neutral. As you can observe that the means of reported+count prompt are less than the remaining two flagging prompts, which signifies that flagging with count was considered more inappropriate, slightly undeserved, and not justified as compared to other two flagging variables. This showed us that our design interventions were definitely resulting in a reaction from the participants, but the reaction was not enough for a conclusive analysis.</p>
              <div class="proj-image-bari"><img src="images/1tirkXEd0h72DU109GtKiEA.png" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1tirkXEd0h72DU109GtKiEA-p-500.png 500w, images/1tirkXEd0h72DU109GtKiEA-p-800.png 800w, images/1tirkXEd0h72DU109GtKiEA.png 1000w" alt="" class="image-12">
                <blockquote class="block-quote"><em>These pretest helped us realize that we were ignoring another factor that was affecting how people perceived harassment ‚Äî </em><strong><em>the harassment itself.</em></strong><em> The harassment prompt of ‚ÄúYou‚Äôre a f**k**g c**t. Do the world a favor and kill yourself.‚Äù was a high aggression harassment.</em></blockquote>
                <p class="paragraph-34">We realized that if given with harassment, participants formed their own opinions on whether the harassment was appropriate, justified, or deserved. With the introduction of our design intervention, we wanted to shift those opinions to inappropriate, undeserved, or unjustified. But if the harassment itself was highly aggressive, we found that these moderating cues were ineffective. This realization opened new avenues for us.<br></p>
                <div class="w-embed w-iframe"><iframe src="https://giphy.com/embed/BKSpzP2p15pAs" width="480" height="215" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
                  <p>
                    <a href="https://giphy.com/gifs/rude-BKSpzP2p15pAs">via GIPHY</a>
                  </p>
                </div>
              </div>
            </div>
          </div>
          <div data-w-tab="Tab 4" class="w-tab-pane">
            <div class="proj-sections">
              <h2 class="heading-9">Overview <span class="text-span-3">üëÅÔ∏è<br></span></h2>
              <div class="proj-image-bari"><img src="images/1oCkNeZ80J2LgAZm6qV35qg.jpeg" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1oCkNeZ80J2LgAZm6qV35qg-p-500.jpeg 500w, images/1oCkNeZ80J2LgAZm6qV35qg-p-800.jpeg 800w, images/1oCkNeZ80J2LgAZm6qV35qg.jpeg 1000w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Prompts tested for Pretest 3<br></em></div>
              </div>
              <p class="paragraph-34">Pretest 2 tested effects of design interventions on the perception of harassment. As mentioned in the previous section, we concluded that the harassment prompt we were using was aggressive and was masking the effects of design interventions. We had decided to go with this aggressive prompt since it was the prompt Lindsay used in her study and we wanted to keep our study as close to Lindsay‚Äôs study.<br><br>For pretest 3 we decided to add an independent variable of low aggression along with the existing harassment prompts. So now our pretest had 2 independent variables of low aggression harassment(LAH) and high aggression harassment(HAH). Our last study also highlighted that there were not many differences between 3 different flagging designs, hence we decided to merge them into just one design for this experiment. Similarly, we dropped our ‚Äòlikes‚Äô design intervention since it was similar to our controlled prompt. This left us with three main design interventions to test ‚Äî control, dislike, and reported. This study used a<strong> 2x3 factorial</strong>, between-subject design; ie. we tested 6 conditions.</p>
              <div class="proj-image-bari"><img src="images/1XxfqsIXYxISge70oLMZ6Aw.jpeg" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1XxfqsIXYxISge70oLMZ6Aw-p-500.jpeg 500w, images/1XxfqsIXYxISge70oLMZ6Aw.jpeg 799w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Design variation and textual variation that were tested in Pretest 3<br></em></div>
              </div>
            </div>
            <div class="proj-sections">
              <h2 class="heading-9">What was tested üß™<span class="text-span-3"><br></span></h2>
              <p class="paragraph-34">The survey was designed in Qualtrics and tested using <a href="http://prolific.co/" target="_blank">Prolific</a>. This survey was tested on 180 participants. The 6 conditions tested were : P1 ‚Äî Low Aggression + Control (31), P2 ‚Äî Low Aggression + Dislikes (38), and P3 ‚Äî Low Aggression + Reported (27), P4 ‚Äî High Aggression + Control (33), P5 ‚Äî Low Aggression + Dislike (28), and P6 ‚Äî Low Aggression + Reported (24).<br>The participants were shown 1 condition prompt. The survey asked participants:<br><br>‚Ü≥ their general <strong>social media behavior and activities</strong>.<br><br>‚Ü≥ <strong>punishment orientation questionnaire</strong> tested their orientation towards a different form of punishments (harsh retributive scale)<br><br>‚Ü≥ <strong>intervention orientation questionnaire</strong> which tested their attitudes related to the conditions they were shown. Example: How likely do you think it is that people would harass you if you posted a comment on this thread?<br><br>‚Ü≥ <strong>feature recall</strong> which tested the number of design variation that the participant spotted in<strong> the prompt</strong></p>
            </div>
            <div class="proj-sections">
              <h2 class="heading-9">Findings üî¨<span class="text-span-3"><br></span></h2>
              <p class="paragraph-34">Quantitative statistical methods such as Two-way ANOVA, Between subject factor Analysis, and Levene‚Äôs test were used to analyze the survey results. The results of Two way ANOVA are statistically significant. As the test was conducted recently, we are still working on analyzing the data. Here is a brief overview of the analysis data we found using a correlation matrix.</p>
              <div class="proj-image-bari"><img src="images/1T9J6G8EmibvBFg6ttDTF8A.png" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1T9J6G8EmibvBFg6ttDTF8A-p-500.png 500w, images/1T9J6G8EmibvBFg6ttDTF8A-p-800.png 800w, images/1T9J6G8EmibvBFg6ttDTF8A-p-1080.png 1080w, images/1T9J6G8EmibvBFg6ttDTF8A.png 1400w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Correlation matrix of Perception vs Intervention orientation questionnaire<br></em></div>
              </div>
              <p class="paragraph-34">The correlation matrix helps researchers understand the relationship between two variables. The green blocks are positive significant correlation, and the red blocks are negative significant correlation. The values in the correlation matrix lie between -1 to 1. Extreme values towards -1 or 1 signify a strong correlation. A positive correlation indicates that when the value of one variable increases the value of other variables also tends to increase. Similarly, a negative correlation indicates that when the value of one variable increases, the value of another value tends to decrease. Unfortunately, the correlation matrix cannot exactly pinpoint which variable is affecting the other. Example: In the above diagram the co-efficient value of ‚ÄúHow offended are you by this post?‚Äù vs ‚ÄúHow likely would you be to report Amy‚Äôs post for harassment?‚Äù is a positive correlation of 0.534 (high correlation). We can infer that as the participants get offended by the post, they are more likely to report the post for harassment. Similarly, we can see that a lot of correlations hold true to the ideal hypothesis.</p>
              <div class="proj-image-bari"><img src="images/1X9WoSnRhz3C2PW9CSInRoQ.png" sizes="(max-width: 479px) 90vw, (max-width: 767px) 80vw, (max-width: 991px) 70vw, 60vw" srcset="images/1X9WoSnRhz3C2PW9CSInRoQ-p-500.png 500w, images/1X9WoSnRhz3C2PW9CSInRoQ.png 926w" alt="" class="image-12">
                <div class="proj-image-caption"><em>Manipulation check question that we asked at the end of the survey<br></em></div>
              </div>
              <p class="paragraph-34">The original number of prompts were like (181), dislike (66), reported (51), and comments (0). As you can see reported was the most noticed design manipulation with 44/51 users noticing this intervention. This helps us understand that the design intervention of reported was definitely noticed by the users.</p>
              <div class="w-embed w-iframe"><iframe src="https://giphy.com/embed/KVKG8XoDvr1du" width="480" height="194" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
                <p>
                  <a href="https://giphy.com/gifs/car-the-hangover-language-KVKG8XoDvr1du">via GIPHY</a>
                </p>
              </div>
              <p class="paragraph-34"><strong>To understand how the design intervention of original, dislike and reported affected the user‚Äôs perception of harassment </strong>I decided to compare the Likert scale means between LAH and HAH variables. Here are some of my findings:<br><br>‚Ü≥ It is surprising to find that the low aggression harassment participants (LAH) found harassment more appropriate, deserved, and justified than the high aggression harassment participants. LAH participants also agreed more with the harassment. This gives us a better idea of how the language of harassment itself can make a difference in the perception of justice.<br><br>‚Ü≥ Similarly, the high aggression participants (HAH) found the post more offensive.<br><br>‚Ü≥ The likeliness of disliking Amy‚Äôs post, and adding a comment to the post was higher in the HAH. This could be a result of the post being more aggressive than the LAH. It might very well signify that users tend to intervene if the harassment is aggressive.<br><br>‚Ü≥ Also, the likeliness of calling out Amy as well as calling out Sarah was higher in the HAH prompts which featured dislike and report intervention.<br><br>‚Ü≥ Participants with dislike prompts were more offended by the post as compared to the reported ones. This could mean that their feeling of offense could stem from others disliking the post. It could also be an effect of users perceiving reporting as a system‚Äôs intervention.<br><br>‚Ü≥ The likeliness of disliking Amy‚Äôs post and calling out Sarah was higher in the dislike prompt as compared to the report.<br><br>‚Ü≥ Participants with the reported prompt found harassment to be more deserved and agreed more with the harassment than the dislike prompt. Also, the likeliness of calling out Amy was higher in the reported as compared to dislike prompt. It could be a result of reporting being a system intervention or reporting being a more serious cue than dislike, which is a cue assessed by the community.</p>
            </div>
          </div>
        </div>
      </div>
      <div class="div-block-37-copy">
        <a href="#Main-page" class="button-3-copy w-button">Go up<br>‚Üë</a>
      </div>
    </div>
  </div>
  <footer id="footer" data-w-id="18a22958-7b7e-e0d6-7228-168dee297925" class="footer">
    <div class="container-3 w-container">
      <div class="footer-flex-container">
        <div class="div-block-51">
          <ul role="list" class="list w-list-unstyled">
            <li class="list-item">
              <a href="index.html" class="footer-link">Home</a>
            </li>
            <li>
              <a href="about.html" class="footer-link">About</a>
            </li>
            <li>
              <a href="documents/ShriyaHardikar_Resume.pdf" target="_blank" class="footer-link">Resume</a>
            </li>
          </ul>
        </div>
        <div class="div-block-51-copy">
          <ul role="list" class="list w-list-unstyled">
            <li class="list-item">
              <a href="godaddy.html" class="footer-link">1. GoDaddy</a>
              <a href="pawls.html" class="footer-link">2. PAWLS</a>
            </li>
            <li>
              <a href="moderating-online-harassment.html" aria-current="page" class="footer-link w--current">3. Moderating online harassment using design and textual interventions</a>
            </li>
            <li>
              <a href="godaddy-internship.html" class="footer-link">4. GoDaddy Internship</a>
            </li>
            <li>
              <a href="bariatric-surgery-decision-aid.html" class="footer-link">5. Bariatric Surgery Decision Aid</a>
            </li>
            <li>
              <a href="saute.html" class="footer-link">6. Saut√© </a>
            </li>
          </ul>
        </div>
      </div>
      <div class="div-block-53">
        <div class="div-block-52">
          <p class="para7678">Contact me<br>
            <a href="mailto:shriyah@umich.edu?subject=Shriya&#x27;s%20email" class="link-20">shriyah@umich.edu</a>
          </p>
          <div class="div-block-43">
            <a href="https://www.linkedin.com/in/shriyahardikar/" target="_blank" class="link-block-5 w-inline-block">
              <p class="paragraph-34374388"><span class="text-span-30">ÔÇå</span><br></p>
            </a>
            <a href="https://www.facebook.com/shriya.hardikar" target="_blank" class="link-block-5 w-inline-block">
              <p class="paragraph-34374388"><span class="text-span-30">ÔÇÇ</span><br></p>
            </a>
            <a href="https://www.instagram.com/hardy16_/" target="_blank" class="link-block-5 w-inline-block">
              <p class="paragraph-34374388"><span class="text-span-30">ÔÖ≠</span><br></p>
            </a>
            <a href="https://twitter.com/shriyahardy" target="_blank" class="link-block-5 w-inline-block">
              <p class="paragraph-34374388"><span class="text-span-30">ÔÇÅ</span><br></p>
            </a>
            <a href="https://medium.com/@hardy16_" target="_blank" class="link-block-5 w-inline-block">
              <p class="paragraph-34374388"><span class="text-span-30">Ôà∫</span><br></p>
            </a>
          </div>
        </div>
        <div class="text-block-66"> Designed by Shriya with <span class="text-span-54">ÔÄÑ </span>using <a href="https://webflow.com/" target="_blank"><span class="text-span-55">Webflow<br></span></a>2021</div>
      </div>
    </div>
  </footer>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5ffff08ec0ca0118c7ab2543" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>
